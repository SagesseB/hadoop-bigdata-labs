# Hadoop Big Data Labs

Objectif du projet
  Ce projet a pour objectif la **prise en main pratique de lâ€™Ã©cosystÃ¨me Big Data Hadoop, Ã  travers la mise en place dâ€™un cluster Hadoop multi-nÅ“uds avec Docker, la manipulation du HDFS, puis le dÃ©veloppement et lâ€™exÃ©cution dâ€™applications MapReduce en Java.
  Lâ€™ensemble des travaux a Ã©tÃ© rÃ©alisÃ© pas Ã  pas afin de comprendre le rÃ´le de chaque composant et les interactions entre eux.

Environnement technique
  SystÃ¨me dâ€™exploitation : Ubuntu (WSL sous Windows 11)
  Virtualisation / Conteneurisation : Docker
  Framework Big Data : Hadoop
  Langage de programmation : Java
  Gestion de projet Java : Maven
  Gestion de version : Git & GitHub

Structure du projet
  hadoop-bigdata-labs/
  â”‚
  â”œâ”€â”€ lab1/                # Programmation avec lâ€™API HDFS
  â”œâ”€â”€ lab3/                # Programmation MapReduce (WordCount)
  â”œâ”€â”€ docker/              # Fichiers liÃ©s Ã  Docker
  â”œâ”€â”€ data/                # DonnÃ©es locales
  â”œâ”€â”€ namenode/            # Volume NameNode
  â”œâ”€â”€ datanode/            # Volume DataNode
  â”œâ”€â”€ screenshots/         # Captures dâ€™Ã©cran demandÃ©es
  â”œâ”€â”€ docs/                # Rapports et documents
  â”œâ”€â”€ docker-compose.yml   # Configuration du cluster Hadoop
  â””â”€â”€ README.md            # Documentation du projet

Lab 1 â€” Programmation avec lâ€™API HDFS
  Objectifs
    Comprendre le fonctionnement du HDFS
    Manipuler les fichiers via lâ€™API Hadoop
    CrÃ©er, lire et Ã©crire des fichiers dans HDFS
  RÃ©sultats
    Connexion rÃ©ussie au cluster Hadoop
    CrÃ©ation de rÃ©pertoires HDFS
    Transfert de fichiers depuis le systÃ¨me local vers HDFS

Lab 3 â€” Programmation MapReduce (WordCount)
  Objectifs
    DÃ©velopper une application MapReduce en Java
    Compiler le projet avec Maven
    ExÃ©cuter un job MapReduce sur le cluster Hadoop

  Application rÃ©alisÃ©e
    WordCount : comptage du nombre dâ€™occurrences de chaque mot dans un fichier texte stockÃ© sur HDFS
  
  RÃ©sultat obtenu
    Docker   1
    Hadoop  1
    Test    1
    partage 1

Le job MapReduce sâ€™est exÃ©cutÃ© avec succÃ¨s, comme confirmÃ© par le fichier SUCCESS gÃ©nÃ©rÃ© dans HDFS.

Captures dâ€™Ã©cran
  Les captures dâ€™Ã©cran suivantes sont disponibles dans le dossier `screenshots/` :
  Interface Web du NameNode
  Interface YARN ResourceManager
  ExÃ©cution des commandes Hadoop et MapReduce

Conclusion
  Ce projet mâ€™a permis de comprendre concrÃ¨tement le fonctionnement dâ€™un cluster Hadoop, du stockage distribuÃ© avec HDFS jusquâ€™au traitement massif des donnÃ©es avec MapReduce.
  Les compÃ©tences acquises constituent une base solide pour aborder des technologies Big Data plus avancÃ©es telles que Spark, Hive ou Kafka.

ğŸ“Œ *Projet rÃ©alisÃ© dans un cadre pÃ©dagogique encadrÃ©.*
